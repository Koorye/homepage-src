---
title: 面向高效的视觉语言大模型设计
date: 2024-10-9 09:15:00
tags: [深度学习,大模型,效率]
categories: 深度学习
description: 本文总结了面向高效的视觉语言大模型设计的方法，包括自主构造数据、对比解码、视觉提示、启发式设计等方面的方法。
---

# 引言

1\. 随着大模型的发展和数据量的不断增加，预训练大模型逐渐拥有作为 __“世界模型”__ 的潜力

2\. 现有工作逐渐从从头训练模型，转为大模型的 __适配__ ，以及 __推理__ 时的 __免训练__ 增强

3\. 比起学习新知识， __利用和激发预训练大模型__ 的知识成为新的热点

# 方法

## 自主构造数据

**Learning by Correction** \(CVPR 24\)

通过词法分析构造错误答案和纠正方式，微调模型以提高泛化能力

![](https://s2.loli.net/2025/03/06/YT6jiDfO7uQswxc.png)

**List Items One by One** \(COLM 24 UCSD\, Microsoft\)

提出逐一列出图像中物体的全新任务，并利用开放词汇检测器构造带密集注释的数据集

**![](https://s2.loli.net/2025/03/06/KNv5jBkf94UVDOS.png)**

**Visual Delta Generator** \(CVPR 24 Meta\)

学习一个生成两张图像差异的VLM，自动化构造组合检索任务的训练数据集

![](https://s2.loli.net/2025/03/06/HbBs1iIvGlKZqm8.png)

**总结：**

任务设计上：一种是 __自定义代理任务__ ，并认为这种代理任务对下游任务有所帮助；一种是某个 __特定的下游任务__

数据构造上：一种是 __提示模型自身__ ；一种是 __结合外部工具__ ，如目标检测器、分割器等

## 对比解码

**Contrastive Region Guidance** \(ECCV 24 UNC\)

通过掩码前后图像的对比增强定位能力

![](https://s2.loli.net/2025/03/06/Y7Ibsr3ZitSHoP6.png)

## 视觉提示

**FALIP** \(ECCV 24\)

一种视觉提示方法，将关注区域转换为高斯分布并展平，嵌入到注意力图的cls行中，实现对目标区域的关注

![](https://s2.loli.net/2025/03/06/Ehos2eRtDnJKxdI.png)

## 启发式设计

**Rephrase\, Augment\, Reason** \(ICLR 24\)

获取关键词、目标和图像描述，利用LLM重述问题以精准预测

![](https://s2.loli.net/2025/03/06/STIdor6GBiVkRCP.png)

**Chain of Symbol** \(COLM 24 西湖\)

用浓缩符号取代文字，用更少的token提升性能

![](https://s2.loli.net/2025/03/06/xDK3t8p6YSyHv1R.png)

**LoRAHub** \(COLM 24\)

搜索一组已知任务上学习的LoRA在未知任务上权重的线性组合

![](https://s2.loli.net/2025/03/06/QiecFEN5ZmVtkqd.png)

**Consisitency and Uncertainty** \(CVPR 24\)

学习小模型生成原问题的近似问题，评估黑盒大模型回答的一致性

![](https://s2.loli.net/2025/03/06/6iPKNt9b4zOcjEI.png)

## 总结

1. 在基于预训练大模型的范式中， __强大的预训练模型__ 是最重要的，所有范式的关键都在于 __利用预训练知识__ ，而不是学习新知识

2. 上述范式通常非常直观，不存在深入的 __理论__ 知识

3. 因此，上述范式的重点通常是探索 __有趣的问题__ （幻觉、效率、公平性等）或 __特定下游任务__ （定位、组合检索等），而不是对适配过程进行深入的研究


