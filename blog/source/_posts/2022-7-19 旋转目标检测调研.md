---
title: 旋转目标检测的调研
date: 2022-7-19 19:47:00
tags: [深度学习,目标检测]
categories: 深度学习
description: 本文对旋转目标检测的难点、现有检测方法、数据集等进行了调研，希望能找到一些发展方向。
---

# 旋转目标检测调研
## 1. 概述
深度学习在传统目标检测领域取得了巨大成功，面对通用目标检测数据集如Pascal VOC、COCO等，基于深度学习的目标检测方法已经能达到不错的性能，同时目标检测方法也在自动驾驶、病虫害检测、医学图像识别等领域取得了重要贡献，并拥有广阔前景。

不过一些非传统的目标检测领域，如3D目标检测(双目图像、点云)、微小目标检测(无人机视觉图像、卫星遥感图像)等仍处在探索阶段，还有很大的提升空间。

卫星遥感图像是一类特殊的图像，与通用目标相比，遥感图像的目标具有尺度差异大、目标分布密集等特点。同时，由于遥感目标具有明确的方向性，针对遥感目标往往设计了特殊的边界框。与传统目标的边界框相比，遥感目标的边界框往往是倾斜的，且不一定是矩形而是普通的四边形。针对这一特殊领域，各种旋转目标检测方法应运而生。本文对旋转目标和典型旋转目标检测方法进行介绍，对其特点进行分析，希望能找到一些发展方向。

## 2. 动机
本文仅作个人记录使用，希望能找到旋转目标检测领域的难点和针对性问题，分析现有检测方法及其针对的问题领域，并为未来的研究提供思路。

## 3. 旋转目标介绍
旋转目标是一类特殊的目标，往往只存在于遥感图像这样有明确方向性的图像中。传统目标检测从平视的角度出发，很难用非横平竖直的边界框表示；而遥感目标从俯视的角度出发，可以用一个倾斜矩形(或四边形)表示，这样的表示也为目标检测带来了新的问题。

### 3.1. 旋转目标数据集
#### 3.1.1. DOTA
DOTA 数据集是用于航拍图像中的目标检测的大型图像数据集。 它可用于发现和评估航拍图像中的物体。DOTA-v1.0 包含来自不同传感器和平台的 2806 幅航拍图像。

DOTA数据集采用4个顶点$(x_1,y_1,x_2,y_2,x_3,y_3,x_4,y_4)$来表示边界框，顶点按顺时针排列，起始点为物体的头部方向或左上角点，以及一个类别标签和一个表示是否困难的标签。

![[Pasted image 20220719234748.png#center|DOTA数据集示例]]

DOTA数据集具有1.0, 1.5, 2.0三个版本，1.5和2.0对上一版本的注释进行更新并增加注释。

#### 3.1.2. HRSC2016
High-resolution ship collections 2016(HRSC2016)是一个用于科学研究的数据集，所有图像都是从谷歌地球上收集，具有3个大类、27个小类。

### 3.2. 旋转目标的表示方法
为了对旋转目标进行回归，需要通过若干个参数对旋转目标的表示进行定义。

#### 3.2.1. 角度表示法
这一表示法将旋转目标边界框(OBB)看作水平目标检测框的旋转(HBB)表示，采用$(x,y,w,h,\theta)$五个参数定义OBB。根据$\theta$，不同机构又提出了不同的表示方法：
- OpenCV表示法：定义$\theta\in (0,90\degree]$为x轴上方最靠近的边与x轴所成的正锐角或直角
- 长边表示法：定义$\theta\in[-90\degree,90\degree)$为长边与x轴所成的角

![](https://s2.loli.net/2025/03/06/fM4g25OdvZmcoBl.png)

#### 3.2.2. 内切表示法
这一表示法(很多文章称其为八参数表示法，但是其实许多论文里用六参数也实现了类似效果，故我称其为内切表示法)将OBB看作一个水平矩形的内切，最早在Gliding Vertex(TPAMI 2020)中被提出，采用水平矩形+四个顶点的偏移来表示一个旋转四边形，这一定义方法需要$(x,y,w,h,\alpha_1,\alpha_2,\alpha_3,\alpha_4)$八个参数。

![](https://s2.loli.net/2025/03/06/CUt2R9xOvVrsej3.png)

BBAVectors(WACV 2021)中则采用水平矩形宽高+内切矩形中心到上下左右边界的距离来定义一个旋转矩形，通过$(t,r,b,l,w,h)$表示。

![](https://s2.loli.net/2025/03/06/lqIxdUeMCpZ4OXV.png)

#### 3.2.3. 其它表示法
aProNet(ISPRS 2021)中采用方向角来表示旋转矩形，具体来说，通过两个向量$(apro_x,0),(0,apro_y)$将OBB的长轴投影到x轴和y轴上，从而通过六个参数$(x,y,w,h,apro_x,apro_y)$表示一个旋转矩形。

![](https://s2.loli.net/2025/03/06/EqvmYbf4trD87sH.png)

除此之外很多论文提出了自己的表示方法，此处就不一一介绍了。

### 3.3. 旋转目标的难点
由于旋转目标在定义上与通用目标的差距，以及遥感目标本身具有的各种特性，旋转目标存在其独特的难点。

#### 3.3.1. 如何定义边界
OBB的定义问题会造成一些歧义，例如在角度的定义上就存在边界问题。角度表示法往往把OBB的角度约束在$(-90\degree,90\degree],(0,90\degree)$等范围内，这往往会导致回归的方式变得复杂。

![](https://s2.loli.net/2025/03/06/nXLamgJ7zeBSf9D.png)

在上图中，蓝色、红色、绿色分别表示建议框、预测框和真值框，左边采用OpenCV表示法(旧版，角度范围在$(-90\degree,0)$)，右边采用长边表示法。对于左边来说，建议框只需向左旋转很小的角度便可以与真值重合，然而边界的定义迫使它需要向右旋转很大的角度；对于右边来说也面临同样的问题。

![](https://s2.loli.net/2025/03/06/VRxCpwLQMeIuyro.png)

另一方面，OpenCV表示法会在边交换时发生突变，当预测框旋转的角度超出边界时，与x轴上方最近的边就会发生改变，从而引起角度、边的长度发生突变，导致损失函数不连续，如上图所示，进一步提升回归难度。

![](https://s2.loli.net/2025/03/06/dmYOvVFk12LxMzr.png)

而在内切表示法中也存在类似问题，建议框各定义只需顺时针偏移很小的距离就可以与真值重合，然而边界的定义迫使它需要逆时针偏移很大的距离。这样的定义使得回归变得复杂且具有歧义，不利于预测结果。

#### 3.3.2. 如何提取和定位旋转特征
旋转目标的特征分布也不是横平竖直的，由于传统的CNN不具有旋转等变性，这导致CNN在不同旋转角度的同类目标上可能提取到截然不同的特征；另一方面，对于多阶段网络来说，在得到OBB之后，如何在不与特征图对齐的旋转矩形区域中提取有效特征也是一个问题。

#### 3.3.3. 如何计算回归损失
旋转目标的损失函数需要重新设计，通用目标检测的HBB是横平竖直的，这使得IoU的计算可以抽象为若干个矩形的面积运算，简单且可导；而旋转目标的OBB具有杂乱的方向，其交集、并集的形状并不是标准的四边形，无法使用HBB的IoU进行计算，如何设计针对OBB的简单且有效的回归损失也是一个问题。

## 4. 现有检测方法
基于上述难点，很多检测方法从不同的角度出发以解决问题，下面从难点的角度出发对解决方法的发展进行介绍。

### 4.1. 在边界上的探索
这类检测方法旨在提出更有效表示OBB的定义，以提供更容易和稳定回归的策略。

#### 4.1.1. 角度表示法
许多方法采用中心坐标、宽高和角度的方式来表示一个OBB，这仍然是当今的主流方法。许多方法直接在通用目标检测框架，如FCOS、RetinaNet上进行改进，在BBox Head上添加了一层角度参数的输出(即将输出通道从4个改为5个)，从而以$(x,y,w,h,\theta)$五参数的形式进行回归。

![](https://s2.loli.net/2025/03/06/A7SCV2grYjFNuEM.png)

如上图，FCOSR在FCOS的基础上对BBox Head进行改动，添加了一个预测角度的通道，并对center sampling、label assignment等策略进行改动，就实现了旋转目标的预测。

#### 4.1.2. 内切表示法
角度表示法存在边界问题，导致回归不能以理想的形式进行。一些方法提出内切四边形的方法来表示一个OBB，Gliding Vertex就采用旋转四边形+外接水平矩形的方式表示一个OBB。

![](https://s2.loli.net/2025/03/06/tvxBoI6zMNrCync.png)

如上图，Gliding Vertex在Faster RCNN上进行改动，RPN负责预测目标的外接水平矩形，根据水平矩形提取特征后再进行位置和偏移的微调。

![](https://s2.loli.net/2025/03/06/HMItfr1yK62vi7V.png)

Reg Head的输出为$(x,y,w,h,\alpha_1,\alpha_2,\alpha_3,\alpha_4,r)$，其中$\alpha_i$分别表示左上、右上、右下、左下四个顶点向顺时针方向的相对偏移，$r$表示是否使用HBB表示一个目标。一些实验说明内切表示法比角度表示法具有更好的性能。

### 4.2. 在旋转特征上的探索
旋转目标在特征分布上也与传统目标不同，往往具有方向性。如何定位一个旋转目标，以及如何有效提取旋转目标的特征，都是旋转目标检测需要解决的问题。

#### 4.2.1. 如何定位旋转目标
**Anchor-free方法**：这类方法直接采用若干参数来回归OBB，往往没有针对旋转目标特征的特殊设计，如FCOSR。

**Anchor-based方法**：这类方法需要用Anchor与目标进行匹配，与通用目标检测不同，旋转目标检测有更多选择：
1. **直接使用水平anchor对GT OBB进行匹配**：通过计算水平anchor和GT OBB之间的旋转IoU来分配正负样本，值得一提的是，对于两阶段模型来说往往会将所有anchor作为正样本，这是因为水平anchor对OBB的匹配往往效果不好，这些效果不好的样本在后续refine过程中可以得到修正。
2. **使用水平anchor对GT HBB进行匹配**：上述方法存在水平anchor与OBB匹配差的问题，因此有的方法采用anchor与GT OBB的外接水平矩形(HBB)进行匹配，这种方法拥有更高的召回率，但由于anchor与GT OBB的差距过大，也提高了回归难度。
3. **通过对anchor进行不同角度的旋转与GT OBB进行匹配**：上述两种方法在准确率和召回率上分别存在问题，有的方法提出对水平anchor进行不同角度的旋转以产生旋转anchor，再用旋转anchor与GT OBB计算旋转IoU进行匹配。然而这样的方法导致计算量成倍增加(若每隔30度产生一个anchor，在180度的范围内就会产生6倍的anchor)，同时由于anchor是倾斜的，在两阶段模型中提取候选框的特征也需要特殊设计。

![](https://s2.loli.net/2025/03/06/el2YOLXjIiGPJaZ.png)

MMRotate中分别使用方法1和2进行测试，方法2取得了更好的效果。

![](https://s2.loli.net/2025/03/06/yfXTLroxEP7UeaM.png)

R$^3$Det(AAAI 2021)中则对方法2和3进行测试，方法3(RetinaNet-R)对于宽高差异大、密集的目标具有更好的效果。

#### 4.2.2. 如何提取旋转特征
上述方法通过暴力方式密集排列anchor，虽然可以取得一定效果，但是极大增加了计算量，具有大量冗余，一些方法从有效提取特征的角度出发，力图以更准确的特征表示弥补OBB回归的困难。

R$^3$Det(AAAI 2021)用一种coarse to fine的思路解决问题，基于Rotated RetinaNet，首先得到coarse OBB，之后通过FRM进一步精修得到refine OBB。

![](https://s2.loli.net/2025/03/06/UCaybdAMoSucjNp.png)

如下图所示，FRM模块通过一个双路卷积在原特征图上提取感受野更大的特征图，对每个特征点进行过滤保留置信度最大的OBB，之后对于每个OBB，从中提取出中心点和四个顶点，在特征图上根据点坐标通过双线性插值得到每个点的特征，之后将各点特征相加作为该特征点的细化特征，细化特征与原特征求和得到最终特征。

![](https://s2.loli.net/2025/03/06/8BHvlh9e2S1oryN.png)

S2ANet则提出对齐卷积来提取旋转不敏感的特征，通过ARN预测粗略的建议框(无需筛选正负样本)，之后ACL在建议框中进行点采样作为卷积的偏移场，通过对齐卷积提取特征。后一部分称ODM模块，通过ARF主动旋转进行编码，提取方向不变和方向敏感特征，分别用于分类和回归。

![](https://s2.loli.net/2025/03/06/xhBNPsD16ztpGAC.png)

如下图所示，对齐卷积根据每个特征点的建议框按行列采样得到3x3点，每个点包含横纵坐标信息，将这些点作为偏移量进行可变形卷积。对齐卷积可以看作可变形卷积的变种，将自学习的偏移量替换为有监督的回归框信息。

![](https://s2.loli.net/2025/03/06/EB1W8sFy6HcG5i9.png)

ARF则是对卷积核进行多次旋转，在每个方向上进行卷积，产生不同方向的特征图并拼接在一起，从而得到方向敏感特征。为了提取方向不变特征，则要在每个通道上进行所有方向的最大值池化。之后使用方向不变特征进行分类，方向敏感特征进行回归。

### 4.3. 在损失计算上的探索
**IoU-Smooth L1 Loss**：由于IoU在旋转目标中计算复杂且不可导，许多方法采用Smooth L1 Loss代替IoU Loss，然而Smooth L1 Loss并不能很好表示两个OBB的匹配度，同时由于角度的边界性，一些IoU很大的OBB拥有很大的损失，OBB越过边界还会带来突变。SCRDet(ICCV 2019)提出IoU-Smooth L1 Loss，使用Smooth L1 Loss作为方向，IoU作为大小(不可导，因此无法参与梯度方向计算)，从而提供更合理的损失指标，并在OBB越过边界时保证损失的连续。
$$
L=\frac{1}{N}\sum_{n=1}^Nt_n'\sum_{j\in\{x,y,w,h,\theta\}}\frac{L_{reg}(v_{nj}',v_{nj})}{|L_{reg}(v_{nj}',v_{nj})|}|-\log(IoU)|,
$$
其中$L_{reg}(x,y)=SmoothL1(x,y)$。

**Modulated Rotation Loss**：Modulated Rotation Loss(AAAI 2021)同样为了解决上述问题，提出了一种简单有效的方法。对于角度表示法来说，分别计算角度不越过和越过边界两种情况(无法得知角度是否越过边界，边界只是人工假设)的损失，之后取最小值作为最终损失。
$$
\nabla l_{cp}=|t_{x1}-t_{x2}| + |t_{y1}-t_{y2}|,
$$
$$
l_{mr}^{5p}=\min\begin{cases}
|t_{w1}-t_{w2}|+|t_{h1}-t_{h2}|+|t_{\theta1}-t_{\theta2}|+\nabla l_{cp}, \\
|t_{w1}-t_{h2}-\log(r)|+|t_{h1}-t_{w2}+\log(r)|+||t_{\theta1}-t_{\theta2}|-\frac{\pi}{2}|+\nabla l_{cp}, \\
\end{cases}
$$
其中$r=w/h$。假设角度不越过边界，则将中心坐标、宽高和角度与对应真值回归；假设角度越过边界，则宽高发生交换(OpenCV表示法下)，角度也发生90度的突变，故将交换和突变前的预测值与真值回归(亦可以看作是对真值进行同样的交换和突变后与预测值进行回归)。

对于内切表示法来说也存在边界问题，当某个方向的偏移量超过边长度的一半时，向相反方向偏移其实是更好的选择。如下图所示，蓝色a向绿色b偏移其实比蓝色a向绿色a偏移更容易。

![](https://s2.loli.net/2025/03/06/QjslpbtD1zSqKT6.png)

故该方法提出分别对预测的四个顶点顺时针和逆时针交换一位，求三种情况损失的最小值。
$$
l_{mr}^{8p}=\min\begin{cases}
\sum_{i=0}^3(|x_{(i+3)\%4}-x_i^*|+|y_{(i+3)\%4}-y_i^*|),  \\
\sum_{i=0}^3(|x_i-x_i^*|+|y_i-y_i^*|),  \\
\sum_{i=0}^3(|x_{(i+1)\%4}-x_i^*|+|y_{(i+1)\%4}-y_i^*|), \\
\end{cases}
$$

**GWD**：上述方法虽然提出了一些连续性的优化方案，但没有在根本上解决边界的不连续性。GWD(ICML 2021)提出将两个OBB建模为二维高斯分布，之后使用归一化的Wasserstein距离作为指标。

首先将OBB转换为二维高斯分布：
$$
m=(x,y)^T,
$$
$$
\Sigma^{1/2}=RSR^T=\begin{pmatrix}
\cos\theta & -\sin\theta \\ 
\sin\theta & \cos\theta \\
\end{pmatrix}\begin{pmatrix}
\frac{w}{2} & 0 \\ 
0 & \frac{h}{2} \\
\end{pmatrix}\begin{pmatrix}
\cos\theta & \sin\theta \\ 
-\sin\theta & \cos\theta \\
\end{pmatrix}.
$$

![](https://s2.loli.net/2025/03/06/LWtqNlJ7ZaARv1h.png)

之后计算Wasserstein距离：
$$
d^2=\Vert m_1-m_2\Vert_2^2+\text{Tr}(\Sigma_1+\Sigma_2-2(\Sigma_1^{1/2}\Sigma_2\Sigma_1^{1/2})^{1/2}),
$$
进行归一化，构造损失函数：
$$
L_{gwd}=1-\frac{1}{\tau+\sqrt{d^{2}}},\tau\ge1
$$
其中$\tau$用来调整loss的缩放，$\tau$越大，对loss的抑制就越强，作者采用$\tau=2$取得了最优效果。